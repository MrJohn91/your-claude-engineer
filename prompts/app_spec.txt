# Outreach Scraping Preparation Toolkit

A complete outreach lead generation toolkit with a polished web UI for scraping and managing leads from multiple social platforms.

## Tech Stack
- Backend: FastAPI with REST API endpoints
- Frontend: React + Vite + Tailwind CSS + shadcn/ui
- Database: Local storage or Replit database (for search history and saved leads)
- Scraping: Apify API integration
- Config: YAML-based audience targeting

## Features (5 total)

### 1. Target Audience Configuration System
- YAML config file (config/audience.yaml) with predefined filters
- Industries: AI, Web3, blockchain, tech startups
- Roles: Founders, CEOs, Co-founders, BD heads, Product Owners, Growth Leads
- Regions: Germany, broader EU, other European countries, South Asia, Southeast Asia, China
- Platforms: LinkedIn, X, Telegram, TikTok
- Loadable by backend as default UI filter options

### 2. Data Pipeline & API Backend
- Apify API integration for multi-platform contact scraping (all scraping must go through Apify; do not implement custom scrapers with raw HTTP requests or standalone Playwright flows)
- Primary source for location-based leads is Google Maps, accessed exclusively via an appropriate Apify actor (e.g. Google Maps scraper)
- Configurable search filters based on audience config
- Output schema: Name, Role, Company, Platform, Contact link, Region, Notes, Rating, Review Count, Address, Phone, Website
- REST API endpoints:
  - POST /scrape - Run scraping with filters
  - GET /results - Get current search results
  - GET /history - Get search history
  - POST /history - Save search to history
  - GET /leads - Get saved/bookmarked leads
  - POST /leads - Save a lead to bookmarks
  - DELETE /leads/:id - Remove a lead from bookmarks
  - GET /download-csv - Download current results as CSV (manual export, not automatic)
- Environment variables: APIFY_API_TOKEN

### 3. Professional Web UI Dashboard
- React frontend with modern SaaS aesthetic (NO Streamlit/Gradio)
- **Left Sidebar Navigation (main app):**
  - "New Search" link (returns to main search form)
  - "History" section (shows all past searches - clicking a history item loads those results)
  - "Leads" section (shows all saved/bookmarked leads)
- **Main Content Area (lead search page):**
  - Top search form with: Keyword, City, State, Number of results inputs
  - Primary "Find my leads" or "Run Scrape" button
  - "Download CSV" button (manual export - only appears after results are shown)
  - Results table showing: Name, Phone, Website, Address (sortable, paginated)
  - Clicking a row opens detail sidebar
- **Right Detail Sidebar** (opens when clicking a lead):
  - Company/Business name
  - Star rating and review count
  - Phone number
  - Address
  - "Visit Website" button (opens their website in new tab)
  - "Google Maps" button (opens their Google Maps listing in new tab)
  - "Save Lead" button (bookmarks the lead - appears in sidebar "Leads" section)
- **Search History Feature:**
  - All searches are automatically saved to history
  - History persists across sessions (using local storage or database)
  - History shows: search query, date/time, number of results found
  - Clicking a history item reloads those exact results
- **Bookmark/Save Lead Feature:**
  - "Save Lead" button on each result and in detail sidebar
  - Saved leads appear in sidebar "Leads" section
  - Can remove leads from bookmarks
  - Can click into saved leads to view full details
- **Cost Insights Page (separate route, e.g. /cost):**
  - Reads `docs/COST_ESTIMATION.md`
  - Backend converts markdown into structured sections/tables
  - An agent chooses layout/components using a declarative generative-UI pattern (selecting from a safe component library)
  - Frontend renders the generated layout using existing dashboard components (cards, tables, callouts)
  - No scraping controls on this page; it is read-only, for internal/team viewing
- Sortable results table with pagination and hover states
- Loading/progress states during scraping operations ("Searching Google Maps. This may take a minute or two.")
- Light/dark mode toggle with consistent spacing and modern fonts

### 4. Cost Estimation Tool (Markdown + Separate UI Page)
- Primary source of truth is a Markdown document for team reference (no costs on the main lead search dashboard)
- Python script or Jupyter notebook for cost analysis
- Estimates for Apify/scraping tools (per 1k, 10k, 50k records)
- Proxy costs (residential vs datacenter, monthly)
- API usage costs (LinkedIn, X, etc.)
- AI enrichment/parsing costs if applicable
- Output formats: CSV and Markdown tables with assumptions and sources
- File: `docs/COST_ESTIMATION.md` or `tools/cost_estimation.md`

### 5. Complete Documentation & Setup
- Comprehensive README with setup instructions
- Environment variables and API keys configuration guide (APIFY_API_TOKEN only)
- Local development setup (backend and frontend)
- Usage examples for scraping, CSV downloading, search history, bookmarking leads, and viewing the cost insights page
- Cost estimation documentation (Markdown file + separate `/cost` UI page)

## Design Guidelines
- Professional SaaS/lead-gen tool aesthetic
- Clean typography with modern fonts (Inter, Geist)
- Consistent spacing and component design
- Responsive design for desktop and mobile
- Loading states and user feedback
- No generic or ugly UI elements

### UI Inspiration
- Use `ui_reference/leadd-dashboard.png` in the project directory as the primary visual reference (dark sidebar, central table, right detail panel).
- Match the overall layout: dark left sidebar navigation, central leads table, and a right-hand detail panel for the selected lead.
- Do not implement authentication or login flows; the app should behave as if the user is always authenticated.
- Only build screens and components that support this toolkit’s core features (audience filters, scraping, results, exports, cost estimation).

- MANDATORY: UI must be the three-column dashboard from the reference image (dark sidebar | main table | right detail panel). Do NOT build a vertical stacked page with sections like API Health Check, Load Configuration, Scrape Leads as separate blocks.

## File Structure
```
backend/
├── main.py              - FastAPI application
├── scraper.py           - Apify integration
├── database.py          - Local storage/database for history and saved leads
└── requirements.txt     - Python dependencies

frontend/
├── src/
│   ├── components/      - React components
│   ├── pages/          - Main dashboard
│   └── styles/         - Tailwind CSS
├── package.json
└── vite.config.js

config/
└── audience.yaml        - Target audience configuration

docs/
└── COST_ESTIMATION.md   - Cost analysis documentation (separate from UI)

tools/
├── cost_estimation.py   - Cost analysis script (optional, for team reference)
└── cost_estimation.ipynb - Jupyter notebook version (optional)

.env.example            - Environment variables template
README.md              - Complete setup and usage guide
```

## Success Criteria
- Multi-platform scraping works reliably via Apify
- Professional UI matches modern SaaS standards and inspiration image
- Search history persists and allows reloading past searches
- Bookmark/save lead feature works correctly (save, view, remove)
- CSV download exports current results correctly
- Detail sidebar shows all lead information with working action buttons
- Cost estimation documentation is complete (separate from UI)
- Complete documentation enables easy setup
- All components integrate seamlessly
